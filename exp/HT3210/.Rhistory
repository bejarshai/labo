library(Prophet)
install.packages('prophet')
library(prophet)
df <- read.csv('https://github.com/gumdropsteve/datasets/raw/master/views.csv')
names(df) <- c('ds', 'y')
m <- prophet(df)
m <- fbprophet(df)
library(fbprophet)
install.packages('fbprophet')
t<- c(14,25)
no.t <- c(159,152)
datos <- rbind(t,no.t)
datos
colnames(datos, "F", "M")
datos
datos <- colnames("F", "M")
colnames(datos) <- c("F","M")
datos
sum.filas <- apply(datos,1,sum)
sum.filas
datos/sum.filas
table(datos)
datos
table(datos)
sum.cols <- apply(datos,2,sum)
sum.cols <- apply(datos,2,sum)
rel.filas <- datos/sum.filas
rel.cols <- datos/sum.cols
rel.filas
rel.cols
mosaicplot(rel.filas,rel.cols)
mosaicplot(datos)
mosaicplot(datos)
mosaicplot?
x <- c(1,2,3,4,5,6,7,8) # devuelve los enteros de 1 a 6
chisq.test(datos)
test_1 <- chisq.test(datos)
test_1
test_1$observed
summary(test_1)
test_1$expected
n <- c(20,18,12,17,67)
s <- c(6,22,15,13,56)
e <- c(4,6,14,11,35,)
o <- c(10,19,23,40,92)
n <- c(20,18,12,17,67)
s <- c(6,22,15,13,56)
e <- c(4,6,14,11,35)
o <- c(10,19,23,40,92)
rbind(n,s,e,)
rbind(n,s,e,o)
datos2 <- rbind(n,s,e,o)
datos2
colnames(datos2)<-c("A","B","C","D","E")
datos2
sum.filas2 <- apply(datos2,1,sum)
sum.cols2 <- apply(datos2,2,sum)
sum.filas2
sum.cols2
anova.datos2 = aov(sum.filas2 ~ sum.cols2, data=datos2)
test_2 <- chisq.test(datos2)
test_2
test_2 <- chisq.test(datos2)
qchisq(0.99,datos2)
qchisq(0.99,test_2)
qchisq(0.99,datos2)
qchisq(0.99,12)
fisher.test(datos2)
prop.table(datos2)
e.n <- c(37, 1334)
e.p <- c(11,223)
datos3 <- rbind(e.n,e.p)
datos3
colnames(datos3) <- c("c.a","s.a")
datos3
prop.table(datos3)
prop.table(datos3)*100
round(prop.table(datos3)*100,2)
test_3 <- chisq.test(datos3)
test_3
sin.cint <- c(13827,2642, 1871, 4840, 23180)
con.cint <- c(1229, 622, 1287, 4581, 7719)
sin.cint
rbind(sin.cint,con.cint)
tabla1 <- rbind(sin.cint,con.cint)
tabla1
colnames(tabla1) <- c("grave", "menor", "minima", "no")
sin.cint <- c(13827,2642, 1871, 4840)
con.cint <- c(1229, 622, 1287, 4581)
tabla1 <- rbind(sin.cint,con.cint)
colnames(tabla1) <- c("grave", "menor", "minima", "no")
chisq.test(tabla1)
tabla2 <- rbind(borracho,normal)
borracho <- c(14691, 648, 1164, 4444)
tabla2 <- rbind(borracho,normal)
borracho <- c(14691, 648, 1164, 4444)
normal <- c(365, 2616, 1994, 4977)
tabla2 <- rbind(borracho,normal)
colnames(tabla2) <- c("grave", "menor", "minima", "no")
chisq.test(tabla2)
test1 <- chisq.test(tabla1)
test2 <- chisq.test(tabla2)
test1$residuals
test2$residuals
library(corrplot)
corrplot(test1$residuals,is.corr=FALSE)
library(readxl) ##Permite leer archivos xlsx
library(ggplot2) ##Paquete para confeccionar dibujos
library(ggrepel) ##Paquete que manipula etiquetas para gráficos
library(plotrix) ##Paquete para gráficos requerido para la libreria smacof
library(smacof)  ##Paquete para MDS basado en la minimización del stress
library(UsingR)
library(pgirmess)#pruebas a posteriori de kruskal wallis
library(MASS)
library(car)
S1=c(3.3,4.4,4.9,4.9,3.9,4.2,4.7,5.1,4.6,4.5)
S2=c(4.6,4.5,5.0,4.0,4.5,5.2,4.9,5.5,4.8,5.3)
S3=c(6.7,5.8,5.0,4.8,5.3,6.2,5.0,6.4,5.9,5.4)
S4=c(6.3,6.0,6.7,5.5,6.6,6.1,5.3,6.5,6.3,6.8)
supl=cbind(S1,S2,S3,S4)
efic=data.frame("Suplemento"=factor(c(rep(1,10),rep(2,10),rep(3,10),rep(4,10))),
"Eficiencia"=c(S1,S2,S3,S4))
efic
install.packages("ggrepel")
install.packages("plotrix")
install.packages("smacof")
install.packages("UsingR")
install.packages("pgirmess")
library(readxl) ##Permite leer archivos xlsx
library(ggplot2) ##Paquete para confeccionar dibujos
library(ggrepel) ##Paquete que manipula etiquetas para gráficos
library(plotrix) ##Paquete para gráficos requerido para la libreria smacof
library(smacof)  ##Paquete para MDS basado en la minimización del stress
library(UsingR)
library(pgirmess)#pruebas a posteriori de kruskal wallis
library(MASS)
library(car)
medias=apply(sup1,2,mean)
supl=cbind(S1,S2,S3,S4)
efic=data.frame("Suplemento"=factor(c(rep(1,10),rep(2,10),rep(3,10),rep(4,10))),
"Eficiencia"=c(S1,S2,S3,S4))
efic
medias=apply(sup1,2,mean)
medias=apply(supl,2,mean)
desvios=apply(supl,2,sd)
Resumen3=round(cbind(medias,desvios),3)
Resumen3
install.packages("MASS")
install.packages("car")
library(readxl) ##Permite leer archivos xlsx
library(ggplot2) ##Paquete para confeccionar dibujos
library(ggrepel) ##Paquete que manipula etiquetas para gráficos
library(plotrix) ##Paquete para gráficos requerido para la libreria smacof
library(smacof)  ##Paquete para MDS basado en la minimización del stress
library(UsingR)
library(pgirmess)#pruebas a posteriori de kruskal wallis
library(MASS)
library(car)
install.packages("colorspace")
GrupoA=c(25,36,36,25,36,16,25,36,49,36,25)
GrupoB=c(121,36,36,64,36,81,49,25,64,49,121)
GrupoC=c(81,81,36,9,25,36,9,49,169,1,81)
GrupoD=c(25,25,36,25,36,25,25,25,25,25,25)
Tiempos=cbind(GrupoA,GrupoB,GrupoC,GrupoD)
tiempo=data.frame("Grupos"=factor(c(rep(1,11),rep(2,11),rep(3,11),rep(4,11))),
"Tiempos"=c(GrupoA,GrupoB,GrupoC,GrupoD))
tiempo
medias= apply(Tiempos,2,mean)
desvios= apply(Tiempos,2,sd)
Resumen5= round(cbind(medias,desvios),3)
plot5= ggplot(Tiempos.aes(x=Grupos,y=Tiempos,fill=Grupos))
install.packages("ggplot2")
install.packages("ggplot")
plot5= ggplot(Tiempos.aes(x=Grupos,y=Tiempos,fill=Grupos))
plot5= ggplot(Tiempos.aes(x=Grupos,y=Tiempos,fill=Grupos))+
geom_boxplot()
library(ggplot)
library(ggplot2) ##Paquete para confeccionar dibujos
plot5= ggplot(Tiempos.aes(x=Grupos,y=Tiempos,fill=Grupos))+
geom_boxplot()
GrupoA=c(25,36,36,25,36,16,25,36,49,36,25)
GrupoB=c(121,36,36,64,36,81,49,25,64,49,121)
GrupoC=c(81,81,36,9,25,36,9,49,169,1,81)
GrupoD=c(25,25,36,25,36,25,25,25,25,25,25)
Tiempos=cbind(GrupoA,GrupoB,GrupoC,GrupoD)
tiempo=data.frame("Grupos"=factor(c(rep(1,11),rep(2,11),rep(3,11),rep(4,11))),
"Tiempos"=c(GrupoA,GrupoB,GrupoC,GrupoD))
tiempo
medias= apply(Tiempos,2,mean)
desvios= apply(Tiempos,2,sd)
Resumen5= round(cbind(medias,desvios),3)
plot5= ggplot(Tiempos.aes(x=Grupos,y=Tiempos,fill=Grupos))+
geom_boxplot()
plot5= ggplot(tiempo.aes(x=Grupos,y=Tiempos,fill=Grupos))+
geom_boxplot()
plot5= ggplot(tiempo,aes(x=Grupos,y=Tiempos,fill=Grupos))+
geom_boxplot()
plot5
source('C:/Users/usuario/Desktop/CURSOS_VARIOS/2_Maestría_Datos_UTN/2 AÑO/2-AMD-EcoFin/labo/src/rpart/321_rpart_BO.r', echo=TRUE)
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
require("data.table")
require("rlist")
require("rpart")
require("parallel")
#paquetes necesarios para la Bayesian Optimization
require("DiceKriging")
require("mlrMBO")
kBO_iter  <- 100   #cantidad de iteraciones de la Optimizacion Bayesiana
hs  <- makeParamSet(
makeNumericParam("cp"       , lower= -1   , upper=    0.1),
makeIntegerParam("minsplit" , lower=  1L  , upper= 8000L),  #la letra L al final significa ENTERO
makeIntegerParam("minbucket", lower=  1L  , upper= 2000L),
makeIntegerParam("maxdepth" , lower=  3L  , upper=   20L),
forbidden = quote( minbucket > 0.5*minsplit ) )             # minbuket NO PUEDE ser mayor que la mitad de minsplit
ksemilla_azar  <- 102191   #cambiar por la primer semilla
loguear  <- function( reg, arch=NA, folder="./work/", ext=".txt", verbose=TRUE )
{
archivo  <- arch
if( is.na(arch) )  archivo  <- paste0( folder, substitute( reg), ext )
if( !file.exists( archivo ) )  #Escribo los titulos
{
linea  <- paste0( "fecha\t",
paste( list.names(reg), collapse="\t" ), "\n" )
cat( linea, file=archivo )
}
linea  <- paste0( format(Sys.time(), "%Y%m%d %H%M%S"),  "\t",     #la fecha y hora
gsub( ", ", "\t", toString( reg ) ),  "\n" )
cat( linea, file=archivo, append=TRUE )  #grabo al archivo
if( verbose )  cat( linea )   #imprimo por pantalla
}
particionar  <- function( data, division, agrupa="", campo="fold", start=1, seed=NA )
{
if( !is.na( seed)  )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x ) }, division, seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
ArbolSimple  <- function( fold_test, data, param )
{
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",
data= data[ fold != fold_test, ],  #entreno en todo MENOS el fold_test que uso para testing
xval= 0,
control= param )
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,
data[ fold==fold_test, ],  #aplico el modelo sobre los datos de testing
type= "prob")   #quiero que me devuelva probabilidades
prob_baja2  <- prediccion[, "BAJA+2"]  #esta es la probabilidad de baja
#calculo la ganancia
ganancia_testing  <- data[ fold==fold_test ][ prob_baja2 > 1/60,
sum( ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ) )]
return( ganancia_testing )  #esta es la ganancia sobre el fold de testing, NO esta normalizada
}
ArbolesCrossValidation  <- function( data, param, qfolds, pagrupa, semilla )
{
divi  <- rep( 1, qfolds )  # generalmente  c(1, 1, 1, 1, 1 )  cinco unos
particionar( data, divi, seed=semilla, agrupa=pagrupa )  #particiono en dataset en folds
ganancias  <- mcmapply( ArbolSimple,
seq(qfolds), # 1 2 3 4 5
MoreArgs= list( data, param),
SIMPLIFY= FALSE,
mc.cores= 1 )   #se puede subir a qfolds si posee Linux o Mac OS
data[ , fold := NULL ]
#devuelvo la primer ganancia y el promedio
ganancia_promedio  <- mean( unlist( ganancias ) )   #promedio las ganancias
ganancia_promedio_normalizada  <- ganancia_promedio * qfolds  #aqui normalizo la ganancia
return( ganancia_promedio_normalizada )
}
EstimarGanancia  <- function( x )
{
GLOBAL_iteracion  <<-  GLOBAL_iteracion + 1
xval_folds  <- 5
ganancia  <- ArbolesCrossValidation( dataset,
param= x, #los hiperparametros del arbol
qfolds= xval_folds,  #la cantidad de folds
pagrupa= "clase_ternaria",
semilla= ksemilla_azar )
#logueo
xx  <- x
xx$xval_folds  <-  xval_folds
xx$ganancia  <- ganancia
xx$iteracion <- GLOBAL_iteracion
loguear( xx,  arch= archivo_log )
return( ganancia )
}
setwd("C:/Users/usuario/Desktop/CURSOS_VARIOS/2_Maestría_Datos_UTN/2 AÑO/2-AMD-EcoFin/labo/src/rpart")
source('C:/Users/usuario/Desktop/CURSOS_VARIOS/2_Maestría_Datos_UTN/2 AÑO/2-AMD-EcoFin/labo/src/rpart/321_rpart_BO.r', echo=TRUE)
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
require("data.table")
require("rlist")
require("rpart")
require("parallel")
#paquetes necesarios para la Bayesian Optimization
require("DiceKriging")
require("mlrMBO")
kBO_iter  <- 100   #cantidad de iteraciones de la Optimizacion Bayesiana
hs  <- makeParamSet(
makeNumericParam("cp"       , lower= -1   , upper=    0.1),
makeIntegerParam("minsplit" , lower=  1L  , upper= 8000L),  #la letra L al final significa ENTERO
makeIntegerParam("minbucket", lower=  1L  , upper= 2000L),
makeIntegerParam("maxdepth" , lower=  3L  , upper=   20L),
forbidden = quote( minbucket > 0.5*minsplit ) )             # minbuket NO PUEDE ser mayor que la mitad de minsplit
ksemilla_azar  <- 999931   #cambiar por la primer semilla
loguear  <- function( reg, arch=NA, folder="./work/", ext=".txt", verbose=TRUE )
{
archivo  <- arch
if( is.na(arch) )  archivo  <- paste0( folder, substitute( reg), ext )
if( !file.exists( archivo ) )  #Escribo los titulos
{
linea  <- paste0( "fecha\t",
paste( list.names(reg), collapse="\t" ), "\n" )
cat( linea, file=archivo )
}
linea  <- paste0( format(Sys.time(), "%Y%m%d %H%M%S"),  "\t",     #la fecha y hora
gsub( ", ", "\t", toString( reg ) ),  "\n" )
cat( linea, file=archivo, append=TRUE )  #grabo al archivo
if( verbose )  cat( linea )   #imprimo por pantalla
}
particionar  <- function( data, division, agrupa="", campo="fold", start=1, seed=NA )
{
if( !is.na( seed)  )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x ) }, division, seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
ArbolSimple  <- function( fold_test, data, param )
{
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",
data= data[ fold != fold_test, ],  #entreno en todo MENOS el fold_test que uso para testing
xval= 0,
control= param )
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,
data[ fold==fold_test, ],  #aplico el modelo sobre los datos de testing
type= "prob")   #quiero que me devuelva probabilidades
prob_baja2  <- prediccion[, "BAJA+2"]  #esta es la probabilidad de baja
#calculo la ganancia
ganancia_testing  <- data[ fold==fold_test ][ prob_baja2 > 1/60,
sum( ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ) )]
return( ganancia_testing )  #esta es la ganancia sobre el fold de testing, NO esta normalizada
}
ArbolesCrossValidation  <- function( data, param, qfolds, pagrupa, semilla )
{
divi  <- rep( 1, qfolds )  # generalmente  c(1, 1, 1, 1, 1 )  cinco unos
particionar( data, divi, seed=semilla, agrupa=pagrupa )  #particiono en dataset en folds
ganancias  <- mcmapply( ArbolSimple,
seq(qfolds), # 1 2 3 4 5
MoreArgs= list( data, param),
SIMPLIFY= FALSE,
mc.cores= 1 )   #se puede subir a qfolds si posee Linux o Mac OS
data[ , fold := NULL ]
#devuelvo la primer ganancia y el promedio
ganancia_promedio  <- mean( unlist( ganancias ) )   #promedio las ganancias
ganancia_promedio_normalizada  <- ganancia_promedio * qfolds  #aqui normalizo la ganancia
return( ganancia_promedio_normalizada )
}
EstimarGanancia  <- function( x )
{
GLOBAL_iteracion  <<-  GLOBAL_iteracion + 1
xval_folds  <- 5
ganancia  <- ArbolesCrossValidation( dataset,
param= x, #los hiperparametros del arbol
qfolds= xval_folds,  #la cantidad de folds
pagrupa= "clase_ternaria",
semilla= ksemilla_azar )
#logueo
xx  <- x
xx$xval_folds  <-  xval_folds
xx$ganancia  <- ganancia
xx$iteracion <- GLOBAL_iteracion
loguear( xx,  arch= archivo_log )
return( ganancia )
}
setwd("C:/Users/usuario/Desktop/CURSOS_VARIOS/2_Maestría_Datos_UTN/2 AÑO/2-AMD-EcoFin/labo/src/rpart")
#cargo el dataset
dataset  <- fread("./datasets/paquete_premium_202011.csv")   #donde entreno
source('C:/Users/usuario/Desktop/CURSOS_VARIOS/2_Maestría_Datos_UTN/2 AÑO/2-AMD-EcoFin/labo/src/rpart/321_rpart_BO.r', echo=TRUE)
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
require("data.table")
require("rlist")
require("rpart")
require("parallel")
#paquetes necesarios para la Bayesian Optimization
require("DiceKriging")
require("mlrMBO")
kBO_iter  <- 100   #cantidad de iteraciones de la Optimizacion Bayesiana
hs  <- makeParamSet(
makeNumericParam("cp"       , lower= -1   , upper=    0.1),
makeIntegerParam("minsplit" , lower=  1L  , upper= 8000L),  #la letra L al final significa ENTERO
makeIntegerParam("minbucket", lower=  1L  , upper= 2000L),
makeIntegerParam("maxdepth" , lower=  3L  , upper=   20L),
forbidden = quote( minbucket > 0.5*minsplit ) )             # minbuket NO PUEDE ser mayor que la mitad de minsplit
ksemilla_azar  <- 999931   #cambiar por la primer semilla
loguear  <- function( reg, arch=NA, folder="./work/", ext=".txt", verbose=TRUE )
{
archivo  <- arch
if( is.na(arch) )  archivo  <- paste0( folder, substitute( reg), ext )
if( !file.exists( archivo ) )  #Escribo los titulos
{
linea  <- paste0( "fecha\t",
paste( list.names(reg), collapse="\t" ), "\n" )
cat( linea, file=archivo )
}
linea  <- paste0( format(Sys.time(), "%Y%m%d %H%M%S"),  "\t",     #la fecha y hora
gsub( ", ", "\t", toString( reg ) ),  "\n" )
cat( linea, file=archivo, append=TRUE )  #grabo al archivo
if( verbose )  cat( linea )   #imprimo por pantalla
}
particionar  <- function( data, division, agrupa="", campo="fold", start=1, seed=NA )
{
if( !is.na( seed)  )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x ) }, division, seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
ArbolSimple  <- function( fold_test, data, param )
{
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",
data= data[ fold != fold_test, ],  #entreno en todo MENOS el fold_test que uso para testing
xval= 0,
control= param )
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,
data[ fold==fold_test, ],  #aplico el modelo sobre los datos de testing
type= "prob")   #quiero que me devuelva probabilidades
prob_baja2  <- prediccion[, "BAJA+2"]  #esta es la probabilidad de baja
#calculo la ganancia
ganancia_testing  <- data[ fold==fold_test ][ prob_baja2 > 1/60,
sum( ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ) )]
return( ganancia_testing )  #esta es la ganancia sobre el fold de testing, NO esta normalizada
}
ArbolesCrossValidation  <- function( data, param, qfolds, pagrupa, semilla )
{
divi  <- rep( 1, qfolds )  # generalmente  c(1, 1, 1, 1, 1 )  cinco unos
particionar( data, divi, seed=semilla, agrupa=pagrupa )  #particiono en dataset en folds
ganancias  <- mcmapply( ArbolSimple,
seq(qfolds), # 1 2 3 4 5
MoreArgs= list( data, param),
SIMPLIFY= FALSE,
mc.cores= 1 )   #se puede subir a qfolds si posee Linux o Mac OS
data[ , fold := NULL ]
#devuelvo la primer ganancia y el promedio
ganancia_promedio  <- mean( unlist( ganancias ) )   #promedio las ganancias
ganancia_promedio_normalizada  <- ganancia_promedio * qfolds  #aqui normalizo la ganancia
return( ganancia_promedio_normalizada )
}
EstimarGanancia  <- function( x )
{
GLOBAL_iteracion  <<-  GLOBAL_iteracion + 1
xval_folds  <- 5
ganancia  <- ArbolesCrossValidation( dataset,
param= x, #los hiperparametros del arbol
qfolds= xval_folds,  #la cantidad de folds
pagrupa= "clase_ternaria",
semilla= ksemilla_azar )
#logueo
xx  <- x
xx$xval_folds  <-  xval_folds
xx$ganancia  <- ganancia
xx$iteracion <- GLOBAL_iteracion
loguear( xx,  arch= archivo_log )
return( ganancia )
}
setwd("C:/Users/usuario/Desktop/CURSOS_VARIOS/2_Maestría_Datos_UTN/2 AÑO/2-AMD-EcoFin")
#cargo el dataset
dataset  <- fread("./datasets/paquete_premium_202011.csv")   #donde entreno
#creo la carpeta donde va el experimento
# HT  representa  Hiperparameter Tuning
dir.create( "./labo/exp/",  showWarnings = FALSE )
dir.create( "./labo/exp/HT3210/", showWarnings = FALSE )
setwd("C:/Users/usuario/Desktop/CURSOS_VARIOS/2_Maestría_Datos_UTN/2 AÑO/2-AMD-EcoFin/labo/exp/HT3210")   #Establezco el Working Directory DEL EXPERIMENTO
archivo_log  <- "HT321.txt"
archivo_BO   <- "HT321.RDATA"
#leo si ya existe el log, para retomar en caso que se se corte el programa
GLOBAL_iteracion  <- 0
if( file.exists(archivo_log) )
{
tabla_log  <- fread( archivo_log )
GLOBAL_iteracion  <- nrow( tabla_log )
}
funcion_optimizar  <- EstimarGanancia
configureMlr( show.learner.output= FALSE)
#configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar
#por favor, no desesperarse por lo complejo
obj.fun  <- makeSingleObjectiveFunction(
fn=       funcion_optimizar,
minimize= FALSE,   #estoy Maximizando la ganancia
noisy=    TRUE,
par.set=  hs,
has.simple.signature = FALSE
)
ctrl  <- makeMBOControl( save.on.disk.at.time= 600,  save.file.path= archivo_BO)
ctrl  <- setMBOControlTermination(ctrl, iters= kBO_iter )
ctrl  <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())
surr.km  <- makeLearner("regr.km", predict.type= "se", covtype= "matern3_2", control= list(trace= TRUE))
#inicio la optimizacion bayesiana
if( !file.exists( archivo_BO ) ) {
run  <- mbo(obj.fun, learner = surr.km, control = ctrl)
} else  run  <- mboContinue( archivo_BO )   #retomo en caso que ya exista
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
